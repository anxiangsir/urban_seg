# ğŸŒ† Urban Segmentation Project | åŸå¸‚åˆ†å‰²é¡¹ç›®    
[![LICENSE](https://img.shields.io/badge/license-MIT-green)](https://github.com/anxiangsir/urban_seg/blob/main/LICENSE)


## ğŸš€ é¡¹ç›®æ¦‚è¿° | Project Overview
### ä¸­æ–‡
è¿™æ˜¯ä¸€ä¸ªé¢å‘æ–°æ‰‹çš„é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²é¡¹ç›®ã€‚æˆ‘ä»¬ä½¿ç”¨äº†åœ¨**4äº¿å¼ å›¾åƒ**ä¸Šé¢„è®­ç»ƒçš„ [unicomæ¨¡å‹](https://github.com/deepglint/unicom)ï¼Œè¯¥æ¨¡å‹åœ¨é¥æ„Ÿåˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä»…ä½¿ç”¨**4å¼ é¥æ„Ÿå›¾åƒ**è¿›è¡Œè®­ç»ƒå³å¯è·å¾—ä¼˜å¼‚æ•ˆæœã€‚

### English
This is a beginner-friendly semantic segmentation project for remote sensing images. We employ the [unicom model](https://github.com/deepglint/unicom) pre-trained on 400 million images, which demonstrates outstanding performance on remote sensing segmentation tasks. Remarkably, it achieves excellent results with just **4 training images**.

---

## ğŸŒŸ æ•ˆæœå±•ç¤º | Results Showcase
<table>
  <tr>
    <td colspan="2" align="center">
      <b>é¢„æµ‹æ•ˆæœ | Predictions</b>
    </td>
  </tr>
  <tr>
    <td><img src="figures/predict.gif" width="400"></td>
    <td><img src="figures/predict_02.gif" width="400"></td>
  </tr>
  <tr>
    <td colspan="2" align="center">
      <b>æµ‹è¯•æ ·ä¾‹ | Test Samples</b>
    </td>
  </tr>
  <tr>
    <td><img src="figures/test.jpg" width="400"></td>
    <td><img src="figures/test_02.jpg" width="400"></td>
  </tr>
</table>

---

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹ | Quick Start
### å•GPUè®­ç»ƒ | 1-GPU Training
```bash
python train_one_gpu.py  # 200è¡Œæç®€å®ç° | Minimal 200-line implementation
```

### å¤šGPUè®­ç»ƒ | Multi-GPU Training
```shell
torchrun --nproc_per_node 8 train_multi_gpus.py  # é«˜æ€§èƒ½å¤šå¡æ”¯æŒ | High-performance multi-GPU
```

## ğŸ“¦ å®‰è£…æŒ‡å— | Installation
```shell
git clone https://github.com/anxiangsir/urban_seg.git
cd urban_seg
pip install -r requirements.txt
```

## ğŸ“ æ•°æ®å‡†å¤‡ | Data Preparation

### æ•°æ®é›†ç»“æ„ | Dataset Structure
```shell
dataset
â”œâ”€â”€ origin       # 5å¼ å¸¦æ ‡æ³¨çš„åŸå§‹å›¾åƒ | 5 annotated originals
â”œâ”€â”€ test         # 3å¼ æ— æ ‡æ³¨æµ‹è¯•å›¾åƒï¼ˆæœ¬é¡¹ç›®æœªä½¿ç”¨ï¼‰| 3 unlabeled test images (unused)
â””â”€â”€ train        # é€šè¿‡é¢„å¤„ç†ç”Ÿæˆçš„è®­ç»ƒæ•°æ® | Generated by preprocess.py
    â”œâ”€â”€ images   # è®­ç»ƒå›¾åƒ | Training images
    â””â”€â”€ labels   # å¯¹åº”æ ‡ç­¾ | Corresponding labels
```

### æ•°æ®é¢„å¤„ç† | Preprocessing

```shell
python preprocess.py  # éšæœºé‡‡æ ·ç”Ÿæˆè®­ç»ƒé›† | Generate training set via random sampling
```
### é¢„è®­ç»ƒæ¨¡å‹ | Pretrained Models

è¯·ä»è¿™é‡Œä¸‹è½½ï¼š  
https://github.com/deepglint/unicom/releases

```
FP16-ViT-B-32.pt
FP16-ViT-B-16.pt
FP16-ViT-L-14.pt
FP16-ViT-L-14-336px.pt
```

### æ•°æ®é›†ä¸‹è½½ | Dataset Download

CCFå«æ˜Ÿå½±åƒçš„AIåˆ†ç±»ä¸è¯†åˆ«æä¾›çš„æ•°æ®é›†åˆèµ›å¤èµ›è®­ç»ƒé›†ï¼Œä¸€å…±äº”å¼ å«æ˜Ÿé¥æ„Ÿå½±åƒ
[ç™¾åº¦äº‘ç›˜](https://pan.baidu.com/s/1LWBMklOr39yI7fYRQ185Og)ï¼Œå¯†ç ï¼š3ih2

## ğŸ“œ å¼•ç”¨æˆ‘ä»¬ | Citation
```shell
@inproceedings{anxiang_2023_unicom,
  title={Unicom: Universal and Compact Representation Learning for Image Retrieval},
  author={An, Xiang and Deng, Jiankang and Yang, Kaicheng and Li, Jiawei and Feng, Ziyong and Guo, Jia and Yang, Jing and Liu, Tongliang},
  booktitle={ICLR},
  year={2023}
}
```
## ğŸ’¬ äº¤æµç¤¾åŒº | Community

QQç¾¤: 679897018 | QQ Group: 679897018
æ¬¢è¿æäº¤Issueæˆ–åŠ ç¾¤è®¨è®ºï¼ | Welcome to submit issues or join our group!
